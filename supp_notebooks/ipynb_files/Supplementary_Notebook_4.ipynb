{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SingleCellVR Tutorial: RNA Velocity Preprocessing\n",
    "This is a complete tutorial for processing raw scRNA-seq data into a velocity map ready for upload onto [SingleCellVR.com](https://singlecellvr.herokuapp.com/).\n",
    "Due to the amount of raw data collection/processing within the early stages of velocity analysis, users will need access to a remote server that allocates memory and storage for their respective dataset. \n",
    "\n",
    "### The main modules/packages used for this analysis are:\n",
    "1. [velocyto](http://velocyto.org/)\n",
    "2. [STAR](https://physiology.med.cornell.edu/faculty/skrabanek/lab/angsd/lecture_notes/STARmanual.pdf)\n",
    "3. [scVelo](https://scvelo.readthedocs.io/)\n",
    "\n",
    "**NOTE**: There are potential difficulties when downloading the velocyto package- please refer to the [velocyto team github](https://github.com/velocyto-team/velocyto.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocyto analysis can only be done on these particular samples:\n",
    "1. Smartseq\n",
    "2. Dropseq and/or inDrops\n",
    "3. Chromium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples can be downloaded from [GEO](https://www.ncbi.nlm.nih.gov/geo/), where users can also receive specifications about the size of files and types of samples there are within a dataset.\n",
    "[Here](https://www.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA322317&o=acc_s%3Aa) are samples/accession information from GEO for the dataset used within [Nestorowa et. al, 2016](https://ashpublications.org/blood/article/128/8/e20/35749/A-single-cell-resolution-map-of-mouse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [barcodes.txt](https://drive.google.com/file/d/1hgKwaF6Ib1tHgy1wjzxW8-gNyGPSCsJP/view?usp=sharing) includes the SRR number, the cell types, and the cluster group for the Nestorowa dataset. This file will help with coloring and labeling for cells when it is time for visualizing the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shell scripts can take multiple hours/days to run, so a command for uploading scripts to the background of your remote server is necessary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nohup mycommand..... > fileNameProgress.out 2>&1 &\n",
    "#.out can be opened so you can manually view the progress of your command periodically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the terminal, all shell scripts can be run using: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh file.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastqDump.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash #make sure to run this script in whichever directory you want your samples to be downloaded into. \n",
    "\n",
    "BSUB -q bigmulti BSUB -core 5 BSUB -M 64000 BSUB -R rusage[mem=64000] #specs for the particular VPN I used\n",
    "\n",
    "sample_ID=\"/filepath/to/cellSampleNames.txt\" #this file shoould just be a list of all GEO SRR samples within nestorowaBarcodes.txt\n",
    "\n",
    "for sample in $(cat $sample_ID); do\n",
    "  echo fastq-dump --gzip $sample;\n",
    "        fastq-dump --gzip ${sample} #gzip step is added to make all samples downloaded as file.fastq.gz\n",
    "done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastq-dump can take approximately one week depending on how many RNA-seq files need to be retrieved for a dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fastqToSam.sh\n",
    "Script edited from this [scRNA-seq pipeline](https://github.com/JunyueC/sci-CAR_analysis/blob/master/scRNA_seq_pipe/scRNA_seq_pipeline.sh), but edited to apply to single-end sequencing data (Nestorowa was using single-end fastq files). \n",
    "\n",
    "**NOTE**: Barcodes are extremeley necessary if you want to include coloring/clustering for your velocity file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure to load/import samtools for the remaining shell scripts\n",
    "\n",
    "!/bin/bash \n",
    "\n",
    "#BSUB -q bigmulti #BSUB -core 5 #BSUB -M 64000 #BSUB -R rusage[mem=64000]\n",
    "\n",
    "fastq_folder=\"/filepath/to/fastq/\"\n",
    "input_folder=$fastq_folder\n",
    "\n",
    "all_output_folder=\"/filepath/to/output/\"\n",
    "\n",
    "sample_ID=\"/filepath/to/sampleNames.txt\" \n",
    "\n",
    "gtf_file=\"/filepath/to/genome_file.gtf\" #this can be found on ensembl.org and can be obtained using !wget command\n",
    "\n",
    "core=8 #memory specs \n",
    "\n",
    "cutoff=200 #see STAR module for information on this amount\n",
    "\n",
    "index=\"/filepath/to/genomeIndex/\" #location for genome index which can be retrieved through STAR\n",
    "\n",
    "script_folder=\"/filepath/to/scriptFile/\" #change back to the script path if needed\n",
    "script_path=/filepath/to/scriptfile\n",
    "\n",
    "python_path=\"/filepath/to/anaconda3/bin\"\n",
    "\n",
    "module load STAR/2.5.4b-foss-2016b #change the specs after STAR/ depending on the version you import\n",
    "\n",
    "STAR_output_folder=$all_output_folder/STAR_alignment\n",
    "filtered_sam_folder=$all_output_folder/filtered_sam\n",
    "rmdup_sam_folder=$all_output_folder/rmdup_sam\n",
    "\n",
    "mkdir -p $STAR_output_folder\n",
    "#remove the index from the memory\n",
    "#STAR --genomeDir $index --genomeLoad Remove\n",
    "#start the alignment\n",
    "echo $input_folder\n",
    "for sample in $(cat $sample_ID); do\n",
    "  echo Aligning $sample;\n",
    "  STAR --runThreadN $core --outSAMstrandField intronMotif --genomeDir $index \\\n",
    "  --readFilesCommand zcat \\\n",
    "  --readFilesIn $input_folder/${sample}.fastq --outFileNamePrefix \\\n",
    "  $STAR_output_folder/${sample} #--genomeLoad LoadAndKeep;\n",
    "done \n",
    "#remember to include the readFilesCommand to gunzip the files\n",
    "STAR --genomeDir $index --genomeLoad Remove\n",
    "echo \"All alignment done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fastqToSam step should take about 1-2 days. Once complete you should have fastq files in a human-readable format (sam). These need to be converted to binary-format (bam) and aligned to proceed with velocyto analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### samToBam.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash\n",
    "\n",
    "#BSUB -q long\n",
    "\n",
    "ls *.sam | xargs -n 1 -I {} sh -c 'samtools view -F 4 -b {} > {}.bam' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bamToSortedBam.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash\n",
    "\n",
    "#BSUB -q long #BSUB -n 4 #BSUB -M 7000\n",
    "\n",
    " for f in *bam\n",
    "  do samtools sort -@ 4 -o ${f/.bam/sorted.bam} $f\n",
    " done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sortedBamRename.sh\n",
    "Filenames will look long and messy at this point, so this renaming step will clean everything up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash\n",
    "\n",
    "#BSUB -q long\n",
    "\n",
    "for f in *.out.samsorted.bam; do\n",
    "    mv -- \"$f\" \"${f%.out.samsorted.bam}sorted.bam\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRR to CellID rename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, convert excel sheet to dictionary and save. This can be done in a jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = pd.read_csv(\"/Users/Desktop/rdc/SRRCellID.txt\") #column 1: SRR names, column 2: cell names\n",
    "dictDf = df.to_dict() #converts SRR names to keys and cell names to values (dictionary)\n",
    "\n",
    "\n",
    "# Serialize data into file:\n",
    "json.dump( dictDf, open( \"dictSRRCellID.json\", 'w' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, this is a shell script that will iterate through the dictionary, finding matching file names and changing them to the cell names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash\n",
    "\n",
    "#BSUB -q long\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.chdir('/File/path/to/all/.sorted.bam)\n",
    "         \n",
    "# Read data from file:\n",
    "names = json.load( open( \"/File/path/to/dictSRRCellID.json\" ) )\n",
    "\n",
    "i = 0\n",
    "root = os.getcwd()\n",
    "for filename in os.listdir('.'):\n",
    "         name = names[filename]\n",
    "except KeyError: \n",
    "    # Filename was not found. Skip. This shouldn't happen, but will prevent your script from breaking for whatever reason. \n",
    "    print(\"Filename \"+filename+\" not found\")\n",
    "    continue    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocyto step: sortedBamToLoom.sh\n",
    "Have this script located where the sorted bam files are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash\n",
    "#BSUB -q bigmulti #BSUB -core 5 #BSUB -M 64000 #BSUB -R rusage[mem=64000]\n",
    "velocyto run-smartseq2 -o /filepath/to/ouputFolder/ -e *.bam genome_file.gtf #same gtf used in fastqToSam.sh step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the outputFolder, there should be your velocity.loom file, which contains the spliced and unspliced counts for your scRNA-seq data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a jupyter notebook, convert the cell cluster names within your nestorowaBarcodes.txt file to a numpy.ndarray and add it as a key to your .loom file. Then you will be able to apply coloring and labelling to the file using the scVelo tutorial below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 'absolute_velocity_umap' key is necessary for uploading the velocity file successfully to SingleCellVR.com.  [Here](https://github.com/qinqian/singlecellvr/blob/master/examples/velocity_3d_scale.ipynb) is a notebook with steps for creating the key. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To further prepare the loom file for uploading onto SingleCellVR.com, follow the scVelo tutorial [here](https://github.com/pinellolab/singlecellvr/blob/master/examples/velocity_3d.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
